{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"H9zfvA_cJpDa","executionInfo":{"status":"ok","timestamp":1724247381954,"user_tz":240,"elapsed":15689,"user":{"displayName":"lssds2024","userId":"00969548683188322270"}}},"outputs":[],"source":["#Importing libraries\n","import numpy as np\n","import scipy.stats as stats\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from matplotlib.animation import FuncAnimation\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from IPython.display import HTML\n","from matplotlib.animation import FuncAnimation\n","from keras.layers import LeakyReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuyUdejgJpDc"},"outputs":[],"source":["# Defining necessary hyper-parameters\n","epochs = 600\n","batch_size = 512\n","plot_freq = 1\n","latent_dim = 1"]},{"cell_type":"markdown","metadata":{"id":"Q-vhP6jVJpDc"},"source":["## Define a Discriminator Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5sz1RYmiJpDd"},"outputs":[],"source":["# Build a discriminator neural network with binary cross entropy loss\n","def build_discriminator(dim):\n","  model = Sequential()\n","  for _ in range(2):\n","    model.add(Dense(64,input_dim=dim,activation=LeakyReLU(alpha=0.1)))\n","  model.add(Dense(1, activation='sigmoid'))\n","\n","  model.compile(Adam(learning_rate=0.002, beta_1=0.5),loss= ________ ,metrics=['accuracy'])\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"u-9Z-xThJpDd"},"source":["## Define a Generator Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNcm4ko9JpDe"},"outputs":[],"source":["# Build a generator neural network\n","def build_generator(latent_dim, output_dim):\n","  model = Sequential()\n","  for _ in range(4):\n","    model.add(Dense(16,input_dim=latent_dim,activation=LeakyReLU(alpha=0.1)))\n","  model.add(Dense(output_dim))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"SrHe0xkAJpDe"},"source":["## Defining and Training the GAN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6bkgRb5JpDe"},"outputs":[],"source":["# Given a generator and a discriminator\n","# Build a GAN by passing the inputs to the generator and its utput to the discriminator\n","def build_GAN(G, D, latent_dim):\n","  D.trainable = False\n","  input_layer = tf.keras.layers.Input((latent_dim,))\n","  X = G( ________ )\n","  output_layer = D( ________ )\n","  GAN = Model(input_layer, output_layer)\n","  GAN.compile(optimizer='adam',loss=________ ,metrics=['accuracy'])\n","  return GAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H7Psx771JpDf"},"outputs":[],"source":["# Generate random uniform noise to input to the generator\n","def generate_input_noise(batch_size, latent_dim):\n","    return np.random.rand(batch_size,latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYZGSudyJpDf"},"outputs":[],"source":["#  Generate real data from a normal distribution to train discriminator\n","def get_real_data(n_samples,output_dim):\n","  np.random.seed(109)\n","  return np.random.randn(n_samples, output_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ustSZAElJpDg"},"outputs":[],"source":["# Build the GAN\n","G = build_generator(latent_dim, 1)\n","D = build_discriminator(1)\n","GAN = build_GAN(G, D, latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eI8lHNamJpDg"},"outputs":[],"source":["# Training the GAN\n","D_loss = []\n","G_loss = []\n","G_predict=[]\n","\n","for step in range(epochs):\n","\n","    np.random.seed(109+step)\n","\n","    # Train discriminator\n","    real_data = get_real_data(batch_size // 2, 1)\n","    fake_data = G.predict(generate_input_noise(batch_size // 2, latent_dim), batch_size=batch_size // 2)\n","    data = np.concatenate((real_data, fake_data), axis=0)\n","\n","    # Write the real and fake samples true labels to train discriminator\n","    labels = np.concatenate((________, ________), axis=0)\n","    # Train the discriminator on the batch\n","    _D_loss, _ = ________\n","\n","    # Train generator\n","    # While generator training we do not want discriminator weights to be adjusted.\n","    D.trainable = False\n","    noise = generate_input_noise(batch_size, latent_dim)\n","\n","    # Write the samples true labels to train the generator\n","    labels = ________\n","    # Train the generator on the batch\n","    _G_loss, _ = ________\n","\n","    D_loss.append(_D_loss)\n","    G_loss.append(_G_loss)\n","\n","    # Generate input test noise of shape (10000, 1) using generate_input_noise\n","    test_noise = ________\n","    # Generate the \"fake\" samples by predicting on the generator G\n","    fake_samples = ________\n","    G_predict.append(fake_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHKtyE18JpDg"},"outputs":[],"source":["### edTest(test_gdloss) ###\n","disc_loss=_D_loss\n","gen_loss=_G_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S73ZlLXKJpDh"},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(20,8))\n","plt.close(fig)\n","def animate(i):\n","  ax[1].cla()\n","  # Plot loss and accuracy\n","  ax[0].plot(np.arange(4*i), G_loss[0:4*i],label='G loss',c='darkred',zorder=50,alpha=0.8)\n","  ax[0].plot(np.arange(4*i), D_loss[0:4*i],label='D loss',c='darkblue',zorder=55,alpha=0.8)\n","  ax[0].set_xlim(-5, epochs+5)\n","  ax[0].set_ylim(-0.05, 1.55)\n","  ax[0].set_xlabel('Epoch')\n","\n","  #Plot distributions\n","  x_vals = np.linspace(-3, 3, 301)\n","  y_vals = stats.norm(0,1).pdf(x_vals)\n","  ax[1].plot(x_vals, y_vals, color='blue', label='real')\n","  ax[1].fill_between(x_vals, np.zeros(len(x_vals)), y_vals, color='blue', alpha=0.6)\n","  a = sns.kdeplot(G_predict[4*i].flatten(), color='red', alpha=0.6, label='GAN', ax=ax[1], shade=True)\n","  ax[1].set_xlim(-3, 3)\n","  ax[1].set_ylim(0, 0.82)\n","  ax[1].set_xlabel('Sample Space')\n","  ax[1].set_ylabel('Probability Density')\n","\n","simulation = FuncAnimation(fig, animate, frames=epochs//4, interval=100, repeat=True)\n","HTML(simulation.to_html5_video())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhNLE1YKJpDh"},"outputs":[],"source":[]}]}